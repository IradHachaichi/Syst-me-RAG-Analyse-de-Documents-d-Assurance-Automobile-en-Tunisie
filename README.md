# ğŸš— SystÃ¨me RAG - Analyse de Documents d'Assurance Automobile en Tunisie
![image1](https://github.com/user-attachments/assets/9049323f-f7ff-4a00-9e03-0281ec25af25)
![image1](https://github.com/user-attachments/assets/c54d2dde-f99c-4bd3-a91b-a785041e989e)

Un systÃ¨me de Retrieval-Augmented Generation (RAG) avancÃ© pour l'analyse intelligente de documents d'assurance avec recherche hybride et gÃ©nÃ©ration de rÃ©ponses par IA.

## ğŸ“‹ Table des matiÃ¨res

- [AperÃ§u du projet](#aperÃ§u-du-projet)
- [Architecture et techniques](#architecture-et-techniques)
- [Technologies utilisÃ©es](#technologies-utilisÃ©es)
- [Pipeline de traitement](#pipeline-de-traitement)

---

## ğŸ¯ AperÃ§u du projet

Ce projet implÃ©mente un systÃ¨me RAG complet pour l'analyse de rapports d'assurance automobile en Tunisie. Il combine plusieurs techniques avancÃ©es de NLP et d'IA pour :
- Extraire et structurer le contenu de documents PDF
- Effectuer des recherches sÃ©mantiques et par mots-clÃ©s
- GÃ©nÃ©rer des rÃ©ponses contextuelles basÃ©es sur les documents
- Ã‰valuer la qualitÃ© des rÃ©ponses gÃ©nÃ©rÃ©es

---

## ğŸ—ï¸ Architecture et techniques

### 1. **Extraction et PrÃ©traitement de Documents**

#### Techniques utilisÃ©es :
- **PyPDF2** : Extraction de texte depuis PDF
- **Parsing structurÃ©** : DÃ©tection automatique de sections, tableaux, et recommandations via regex
- **Normalisation Unicode** : Nettoyage et standardisation du texte (NFKC)
- **Chunking intelligent** : DÃ©coupage avec overlap (1000 tokens, 200 tokens de chevauchement)

#### Patterns de dÃ©tection :
```python
- Marqueurs de pages : r'---\s*PAGE\s+(\d+)\s*---'
- Parties principales : r'^\d+\s*(?:Ã¨re|e)\s*PARTIE\s*:\s*(.+?)$'
- Sections hiÃ©rarchiques : r'^([IVX]+)\.\s+(.+?)$', r'^([A-Z])\.\s+(.+?)$'
- Recommandations : r'Recommandation\s*NÂ°?\s*(\d+)\s*:\s*(.+?)$'
- Tableaux : r'Tableau\s+(\d+)\.\s*(.+?)$'
```

---

### 2. **SystÃ¨me de Recherche Hybride**

#### A. Recherche par mots-clÃ©s (BM25)

**Technique** : BM25 (Best Matching 25) - Okapi
- Algorithme de ranking probabiliste
- Mesure TF-IDF amÃ©liorÃ©e avec saturation
- Tokenisation simple avec nettoyage de ponctuation

**ParamÃ¨tres** :
```python
- Suppression des mots < 3 caractÃ¨res
- Normalisation en minuscules
- Retrait de la ponctuation
```

#### B. Recherche sÃ©mantique (Vector Search)

**ModÃ¨le d'embeddings** : `paraphrase-multilingual-mpnet-base-v2`
- Architecture : MPNet (Masked and Permuted Pre-training)
- Dimension : 768
- Support multilingue (franÃ§ais inclus)
- Normalisation L2 des vecteurs

**MÃ©thode de similaritÃ©** : Cosine Similarity
```
similarity = dot(query_vec, doc_vec) / (||query_vec|| * ||doc_vec||)
```

#### C. Fusion hybride

**StratÃ©gie de pondÃ©ration** :
```python
score_hybride = (0.4 Ã— score_BM25_normalisÃ©) + (0.6 Ã— score_sÃ©mantique_normalisÃ©)
```

**Normalisation** : Min-Max scaling
```python
score_normalisÃ© = score / max(tous_les_scores)
```

**Re-ranking contextuel** :
- Bonus pour prÃ©sence de recommandations (+0.1)
- Bonus pour prÃ©sence de chiffres dans les questions numÃ©riques (+0.1)
- Bonus pour sections principales (+0.05)

---

### 3. **GÃ©nÃ©ration de RÃ©ponses (LLM)**

#### ModÃ¨le : Groq API - `llama-3.1-8b-instant`

**Architecture** : LLaMA 3.1 (8 milliards de paramÃ¨tres)
- OptimisÃ© pour vitesse (inference < 1s)
- Support du franÃ§ais
- Context window : 8192 tokens

**StratÃ©gie de prompting** :
```
Structure :
1. Instructions systÃ¨me (rÃ´le d'expert)
2. Contexte documentaire (top-5 chunks, max 3500 chars)
3. Question utilisateur
4. Consignes de rÃ©ponse (prÃ©cision, citations, structure)
```

**ParamÃ¨tres de gÃ©nÃ©ration** :
```python
temperature = 0.3  # Faible pour rÃ©ponses factuelles
max_tokens = 800    # RÃ©ponses concises
```

---

### 4. **SystÃ¨me d'Ã‰valuation**

#### A. MÃ©triques de RÃ©cupÃ©ration

**Cosine Similarity** : Ã‰value la pertinence des documents rÃ©cupÃ©rÃ©s
```python
cos_sim = Î£(query_vec Â· doc_vec) / n_docs
```

#### B. MÃ©triques de GÃ©nÃ©ration

**BLEU (Bilingual Evaluation Understudy)** :
- Mesure la prÃ©cision des n-grams (1-4 grams)
- Smoothing : MÃ©thode 1 (add-one smoothing)
```python
BLEU = BP Ã— exp(Î£ wâ‚™ log pâ‚™)
```

**ROUGE (Recall-Oriented Understudy for Gisting Evaluation)** :
- ROUGE-1 : Unigrams recall
- ROUGE-2 : Bigrams recall  
- ROUGE-L : Longest Common Subsequence
```python
ROUGE-N = Î£ n-grams_match / Î£ n-grams_rÃ©fÃ©rence
```

---

### 5. **Optimisations de Performance**

#### A. Cache de requÃªtes
- **MÃ©thode** : Hash MD5 des requÃªtes normalisÃ©es
- **Politique** : LRU (Least Recently Used)
- **Taille** : 100 requÃªtes en mÃ©moire
- **Gain** : ~10x plus rapide pour requÃªtes rÃ©pÃ©tÃ©es

#### B. Indexation efficace
- **BM25** : Tokenisation prÃ©-calculÃ©e (pickle)
- **Vector** : Embeddings prÃ©-calculÃ©s (NumPy arrays)
- **Option FAISS** : Pour grandes bases (>1000 docs)

---

## ğŸ› ï¸ Technologies utilisÃ©es

### BibliothÃ¨ques principales
```python
# Extraction de documents
PyPDF2==3.0.1              # Lecture PDF

# NLP et embeddings
sentence-transformers==2.2.2  # Embeddings multilingues
transformers==4.30.0          # Backend pour sentence-transformers

# Recherche
rank-bm25==0.2.2           # Algorithme BM25
faiss-cpu==1.7.4           # Indexation vectorielle (optionnel)
numpy==1.24.3              # Calculs vectoriels

# GÃ©nÃ©ration
openai==1.3.0              # Client API (Groq compatible)

# Ã‰valuation
nltk==3.8.1                # Tokenisation pour BLEU
rouge-score==0.1.2         # MÃ©triques ROUGE

# Interface
gradio==4.0.0              # Interface web interactive

# Utilitaires
python>=3.8
unicodedata                # Normalisation de texte (stdlib)
```

---

## ğŸ“Š Pipeline de traitement

### Phase 1 : Extraction
```
PDF â†’ PyPDF2 â†’ Texte brut â†’ Parsing structurÃ© â†’ Sections + Metadata
                    â†“
            [Cleaning Unicode]
                    â†“
            [DÃ©tection patterns]
                    â†“
        Chunking avec overlap (1000/200)
                    â†“
                JSON structurÃ©
```

### Phase 2 : Indexation
```
Chunks â†’ Sentence Transformer â†’ Embeddings (768d)
  â†“                                    â†“
BM25 Tokenization              Normalisation L2
  â†“                                    â†“
Index BM25 (Okapi)            Vector Index (NumPy/FAISS)
```

### Phase 3 : RequÃªte
```
Question utilisateur
    â†“
    â”œâ”€â†’ BM25 Search (40%) â”€â”
    â””â”€â†’ Semantic Search (60%) â”€â†’ Fusion â†’ Top-K chunks
                                     â†“
                              [Re-ranking contextuel]
                                     â†“
                            Contexte + Prompt â†’ Groq LLM
                                     â†“
                            RÃ©ponse gÃ©nÃ©rÃ©e + Sources
```

### Phase 4 : Ã‰valuation
```
RÃ©ponse gÃ©nÃ©rÃ©e + RÃ©fÃ©rence
    â†“
    â”œâ”€â†’ Cosine Similarity (rÃ©cupÃ©ration)
    â”œâ”€â†’ BLEU (gÃ©nÃ©ration)
    â””â”€â†’ ROUGE-1/2/L (gÃ©nÃ©ration)
    â†“
MÃ©triques d'Ã©valuation
```
